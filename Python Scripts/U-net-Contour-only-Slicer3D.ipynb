{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2e133328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import PIL\n",
    "from PIL import ImageOps\n",
    "from PIL import Image\n",
    "import nrrd\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import imageio\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fb6d4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "img_size= (64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2a06bf2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 17 :  ['2609170', '2467000', '2459017', '2419611', '2413785', '2551521', '1049397', '2591335', '2541392', '2593206', '2386449', '2455275', '2139028', '2377620', '2510278', '862797', '2403028']\n",
      "Number of test samples: 2 :  ['2604993', '2467929']\n"
     ]
    }
   ],
   "source": [
    "#Pick random train and val:\n",
    "path= 'C:/Users/bvtran/OneDrive - Inside MD Anderson/Documents/MRL_data/RD_Center_cropped'\n",
    "datadir= os.listdir(path)\n",
    "remove=['2521725','2570357','2574697','2587907','895844','2547570']\n",
    "for i in remove:\n",
    "    datadir.remove(i)\n",
    "train_dir=random.sample(datadir, 17)\n",
    "for i in range(len(train_dir)):\n",
    "    datadir.remove(train_dir[i])\n",
    "val_dir=random.sample(datadir, 2)\n",
    "train_path=[]\n",
    "val_path=[]\n",
    "for i in range(len(train_dir)):\n",
    "    train_path.append(path+'/'+str(train_dir[i]))\n",
    "for i in range(len(val_dir)):\n",
    "    val_path.append(path+'/'+str(val_dir[i]))    \n",
    "print(\"Number of train samples:\", len(train_dir),\": \",train_dir)\n",
    "print(\"Number of test samples:\", len(val_dir),\": \",val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cdc064e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 15 :  ['2467000', '2609170', '2139028', '1049397', '862797', '2467929', '2403028', '2593206', '2386449', '2591335', '2551521', '2455275', '2510278', '2419611', '2541392']\n",
      "Number of test samples: 2 :  ['2377620', '2459017']\n"
     ]
    }
   ],
   "source": [
    "path= 'C:/Users/bvtran/OneDrive - Inside MD Anderson/Documents/MRL_data/RD_Center_cropped'\n",
    "datadir= os.listdir(path)\n",
    "remove=['2521725','2570357','2574697','2587907','895844','2547570','2377620', '2459017']\n",
    "for i in remove:\n",
    "    datadir.remove(i)\n",
    "train_dir=random.sample(datadir, 15)\n",
    "for i in range(len(train_dir)):\n",
    "    datadir.remove(train_dir[i])\n",
    "val_dir=['2377620', '2459017']\n",
    "train_path=[]\n",
    "val_path=[]\n",
    "for i in range(len(train_dir)):\n",
    "    train_path.append(path+'/'+str(train_dir[i]))\n",
    "for i in range(len(val_dir)):\n",
    "    val_path.append(path+'/'+str(val_dir[i]))    \n",
    "print(\"Number of train samples:\", len(train_dir),\": \",train_dir)\n",
    "print(\"Number of test samples:\", len(val_dir),\": \",val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848bd16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # Zooming out\n",
    "    if zoom_factor < 1:\n",
    "\n",
    "        # Bounding box of the zoomed-out image within the output array\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        # Zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # Zooming in\n",
    "    elif zoom_factor > 1:\n",
    "\n",
    "        # Bounding box of the zoomed-in region within the input array\n",
    "        zh = int(np.round(h / zoom_factor))\n",
    "        zw = int(np.round(w / zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # If zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "265e9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare sequence class to load and vectorize batches of data\n",
    "\n",
    "class tumorMaskData(keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,))\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            data_path= os.listdir(path)\n",
    "            Contour_path=[]\n",
    "            for i in range(len(data_path)):\n",
    "                if (\"Contour\" in data_path[i])==True:\n",
    "                    Contour_path.append(data_path[i]) \n",
    "            contour1, header = nrrd.read(path+'/'+Contour_path[0])\n",
    "            contour2, header = nrrd.read(path+'/'+Contour_path[1])\n",
    "            contour3, header = nrrd.read(path+'/'+Contour_path[2])\n",
    "#             if (\"2547570\" in path)==False:\n",
    "            contour1 = clipped_zoom(contour1, 2)\n",
    "            contour2 = clipped_zoom(contour2, 2)\n",
    "            contour3 = clipped_zoom(contour3, 2)\n",
    "            x[j] = np.stack((contour1*255,contour2*255,contour3*255), axis=-1)\n",
    "            \n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,))\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            data_path= os.listdir(path)\n",
    "            Contour_path=[]\n",
    "            for i in range(len(data_path)):\n",
    "                if (\"Contour\" in data_path[i])==True:\n",
    "                    Contour_path.append(data_path[i])\n",
    "            contour, header = nrrd.read(path+'/'+Contour_path[-1])\n",
    "#             if (\"2547570\" in path)==False:\n",
    "            contour = clipped_zoom(contour, 2)\n",
    "            y[j] =np.expand_dims(contour, 2)\n",
    "            \n",
    "        return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dc906eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 32)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 32)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d (SeparableConv (None, 32, 32, 64)   2400        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         separable_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 32, 32, 64)   4736        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 64)   2112        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16, 16, 64)   0           max_pooling2d[0][0]              \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16, 16, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 16, 16, 128)  8896        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 128)  512         separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 16, 16, 128)  17664       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 128)  512         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 128)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 8, 128)    8320        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 8, 128)    0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 128)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 8, 8, 256)    34176       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 256)    1024        separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 8, 8, 256)    68096       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 256)    1024        separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 256)    33024       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 4, 4, 256)    0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 4, 4, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 4, 4, 256)    590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 256)    1024        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4, 4, 256)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 4, 4, 256)    590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 256)    1024        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 8, 8, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 256)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 256)    65792       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 256)    0           up_sampling2d[0][0]              \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 256)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 8, 8, 128)    295040      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 128)    512         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 128)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 8, 8, 128)    147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 128)    512         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 128)  32896       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 128)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 16, 16, 64)   73792       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 64)   256         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 16, 16, 64)   36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   256         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 64)   8256        up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 64)   0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 32, 32, 32)   18464       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 32)   128         conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 32, 32, 32)   9248        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 32)   128         conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 64, 64, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 32)   2080        up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 32)   0           up_sampling2d_6[0][0]            \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 2)    578         add_6[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 2,058,690\n",
      "Trainable params: 2,054,914\n",
      "Non-trainable params: 3,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def get_model(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "model = get_model(img_size, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "eb6e8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate data Sequences for each split\n",
    "train_gen = tumorMaskData(batch_size, img_size, train_path, train_path)\n",
    "val_gen = tumorMaskData(batch_size, img_size, val_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1770c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 0.4987 - val_loss: 0.3817\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.1388 - val_loss: 0.1122\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0542 - val_loss: 0.0729\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0399 - val_loss: 0.0699\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0750 - val_loss: 0.0671\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 0.0773 - val_loss: 0.1958\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 0.0645 - val_loss: 0.0903\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 1s 114ms/step - loss: 0.0359 - val_loss: 0.0855\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 1s 115ms/step - loss: 0.0347 - val_loss: 0.0835\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 1s 120ms/step - loss: 0.0346 - val_loss: 0.0822\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.0345 - val_loss: 0.0812\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.0345 - val_loss: 0.0803\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 1s 110ms/step - loss: 0.0345 - val_loss: 0.0797\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0345 - val_loss: 0.0793\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 1s 111ms/step - loss: 0.0345 - val_loss: 0.0790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25845537cd0>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=1)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch.\n",
    "epochs = 15\n",
    "model.fit(train_gen, epochs=epochs, validation_data=val_gen,callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cc4ccb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025813AE3700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "#Generate predictions for all images in the validation set\n",
    "val_preds = model.predict(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "48576acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/bvtran/OneDrive - Inside MD Anderson/Documents/MRL_data/python_code/Unet-Contour\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('C:/Users/bvtran/OneDrive - Inside MD Anderson/Documents/MRL_data/python_code/Unet-Contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3103e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('C:/Users/bvtran/OneDrive - Inside MD Anderson/Documents/MRL_data/python_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f0f98222",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAEtCAYAAADHtl7HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdNElEQVR4nO3df7xtdV3n8dc7LoSgBqTQFVC0yB85cnHuIKYV/sDQ/EGWptZ4LetOo5nNmIo1Y2PTD/utM5WGv2CKNAZRkMdo0lXGHB303hQFAa8Zwo0LV1L8QYQKn/ljrQObM/fcs7/77H32Ove8no/Hfuz1e33OPmd9zmd913etnapCkiRJ4/u2eQcgSZK01lhASZIkNbKAkiRJamQBJUmS1MgCSpIkqZEFlCRJUiMLqHUoyXFJKsmGOez7miRPXO39SlpbkpyV5Df64R9IcvUq7beSfM9q7EtrmwXUjCR5TpJLk9ySZE8//KIkmXds+5Lk6yOvO5LcOjL+k43bujMBTim2H0ny4SQ3J7khyZuS3Gsvyx2R5ItJPrxoevW/j4Wf580j8749yR8luT7Jl5P8aZIDF23zXf36X0jyvJF5ByU5ry8OK8kpi/b73kWf6zeSfHpan4s0L/3f/EKOuDHJ25Lcc9r7qaq/raoHjxHPCxYf97OU5PeT7EzytSRXJXn+Estt6XPDzy6K9fZFueGUkfkPTfKBJF9J8rkkP7pom0/o9/nPST6Y5AEj8x7XT/tKkmsWrXf/Rfv8eh/by6b0sawbFlAz0P8hvh74PeC7gKOAnwceAxy0xDoHrFqA+1BV91x4AdcCTxuZds7CcvNovQK+A/gN4H7AQ4Fj6D7jxX4HuHKJbZww8vP87Mj0M4DNwMOB7wUeCfynkfl/AnyD7nf5k8AbknzfyPwPAz8F3LB4h1X15EWf60eA/7ncDyutEU/r/64fCfwb7n7cAHPLF6vhFuBpdLlpC/D6JN8/ukCSw4FXAVfsZf2PjuaGqrqkX2cDcAFwEXAEsBX4iyTf28+/D3A+8J/7+duBv1oU11uBly/eYVVduygf/SvgDuCdk30E61hV+Zrii+5AugX4sWWWOwt4A/C/+uWfSFcUXALcTHewPX1k+UuAnx0ZfwHw4ZHxoivSdgJfpvuHn37eAcDvAzcBnwde3C+/YZkYrwGe2A+fAuwCXklXJPz54hhG4vgeugP+m3RFx9eB94xs85eBTwFfoTvoD57ws34m8OlF0x4NfBT46aViW2Jb24FnjYw/D7iuHz60/zm+d2T+nwOv3ct2dgGn7CPm44DbgQfO+2/Vl6+VvkZzRD/+e8BF/XD1uWYn8A/9tKcCn+xz3EeAR4yseyLwd8DX+rzwDuA3+nmnALtGlj2WroD4IvBPwB/T5c9/6Y+vrwM398t+e5//rgVuBN4I3GNkWy8HdgPXAz+zrzwxxudxIfCyRdPeCLyIZXL4onUe3v8MGZn2fuC/9sNbgY+MzDsUuBV4yKLtPBG4ZpmYfw344Lz/ltbiyxao6Xs03QF7wRjLPg/4TeBewKXAe+gOkiOBlwDnJFm22XrEU+nOAE8Ang38cD/95/p5J9K1svx4wzZHfRfd2c4D6A7gJVXVmcA5wO9Wd6bztJHZzwZOAx4IPIIukQDQX5577Jjx/CAjZ3V9K96fAL9AlwT35kP95b/zkxw3Mj39a3T8mCTfQdcidXtVfXZk/mXAaAvUuJ4P/G1V/cME60qDleRY4CnAJ0Ymnw48CnhYkkfStYr8O+A7gT8DLuwvnx8EvJvuxOQIuhbaH1tiPwfQtcx8ge6E5GjgHVV1Jd1J5EKrzmH9Kr9Ddwxvoju5Oxp4db+t0+hO6E4FjqcrOEb39bwknxrz578HXf4dzUkn0eXcNy6x2olJbkry2ST/eaSlbm9dPUJXWEGXey5bmFFVtwB/z+Q56ewJ1lv3LKCm7z7ATVX1rYUJST7SFwa3JvnBkWUvqKr/U1V30B3c96Rr1fhGVX2ALkk8t2Hfr62qm6vqWuCD/TahK1heV1XXVdWXgN+e8Ge7A/i1qrqtqm6dcBsA/62qru9jec9InFTVYVW1bB+GJKfSNZm/emTyLwKXVtWOJVb7IbqE+xC6s82LRhLWe4GXJrlvku/qtwVwCN3v5SuLtvUVusK31fPpWh+l/cW7k9xMdxn7fwO/NTLvt6vqS32++Dngz6rq0qq6varOBm4DTu5fB9LlqW9W1XnAx5fY30l0l/FfXlW3VNW/LJUzkqTf73/o4/haH99z+kWeDbytqi7vi5D/Mrp+Vf1lVT1izM/hjXRFzV/3+z4A+FPgJX2OX+xDdAXRkXTF4nO565LbVcAe4OVJDkzyJLr8dUg/fyo5KckP0HVLOK9lPXX21+vS8/RPwH2SbFgooqrq+wGS7OLuRet1I8P3o7tkNHqgfYHubGlco/1v/pnuILtz24u2O4kvVtW/TLjuqMVx3q9l5SQnA38J/PhCq1CS+9EVPf96qfWq6kP94DeSvBT4Kl2z/6fpWgIPo7u8cBvwJroWuz10LW/3XrS5e9NdamiJ+7H9tkxW2p+cXlV/s8S80bzzAGBLkpeMTDuI7vgv4B+rarTleKk8dSzwhdGT1H24L13RsSN33b8Tum4N9PsePeGaKDcm+T26YuhxIz/Di4BPVdVH97ZOVX1+ZPTTSX6droD67ar6ZpLTgf9O121iO3AuXW6C7vLeinMS3UnoO6vq643rCVugZuGjdH/kzxhj2dFkcT1wbJLR38n9gX/sh2/hrrMP6P4Rj2s3XdIZ3e4kFl8Wu1tMfcvNvpZfsSQn0vUz+Jmq2jYy6yRgI/CZJDfQdeI/qb9ct1QH/aJvKq+qW6vqF6rq6Kp6EF0hvKOqbgc+C2xIcvzIuiew906h+7IFON9kpXVkNAdcB/xm38q88Dqkqt5Ol6OOTu52l/JSeeo64P5LdExfnHNuousb9H0j+/yO6jpPwxRyY5LXAE8GnlRVXx2Z9QTgR/scdAPw/cAfJPnjJTZ1Zz4CqKpPVdUPVdV3VtUPAw8CPtbPvoIuBy3EcCjw3TTkpP6S47Pw8t3ELKCmrKpuBl4D/GmSH09yzyTflmQTXUe/pVxKV5C8om+yPYXu7o539PM/CTwzySHpnlHywoawzgV+Mckx/R0hZzSsuy+XAd+XZFOSg1nU/E3XYfNBU9oXSR4OvI+uSfw9i2a/l+7y3Kb+9Wq6vhibqur2JAtxHpDuNus/oCtOr+y3fXSS+6VzMt3dLb8Gd/YvOB/49SSHJnkMXYH85yOxfXv/GQAclOTg0X8GI8nqrGl9HtIa8ybg55M8qj/ODk33aJJ70Z14fosuT21I8ky6k6K9+Rhd4fPafhsH98ckdDnnmL5PFX2L/puAP0pyJNx5rC/0Dz0XeEGShyU5hP6YH1eSV9H1ZT21qv5p0ewX0LVwb+pf2+n+N/xqv+6TkxzVDz+ELufc2Xc2ySP6n+2QJL9Md4J4Vj/7XcDDk/xYn3deTdfadVW/7rf10w/sRnPwwmcy4kfpOvN/sOVn1l0soGagqn4X+I/AK+guAd1I12HylXR3nuxtnW8AT6c7k7mJ7tr58xcOCOCP6O4Eu5HujOGcvW1nCW+iuy5/Gd1dLue3/UR7118++3Xgb+jutFncD+EtdJ1Hb07y7nG2me6ZJD+wxOyX0TXJvyV3Pb/kij6W26rqhoUXXX+Ab/bD0F3n/yu6y3afpyu2nlpV3+znfzfd7+YWus/3jKp6/8i+XwTcg+73+Xbg31fV6Nne1XRnukfTfda30l2yWHB6H5PJSutSVW2n64/0x3R3Cn+O/gaSPv89sx//MvATLJGn+lbhp9F1CL+W7s7Xn+hnf4CuFeaGJDf1017Z7+v/JvkqXb56cL+t9wKv69f7XP9+pyQ/uZBjlvBbdK1WO0dy0q/02755UU76BvDVqlrou/QE4FNJbqG7G/t87t5/7N/SFYp7+mVPrarb+m1/ka7f1G/2n9ejuKtfF3Q32Nzab/f+/fBoPoOuRfx/LLpsqgbxs5MkSWpjC5QkSVIjCyhJkqRGFlCSJEmNVlRAJTktydXpvuhwWnd2SdKqMIdJmtTEncj7Z+t8lu4R+Lvonhr73Kr6zPTCk6TZMIdJWomVPIn8JOBzC09TTfIOumfjLJl8knjLn7T+3FRV9513EHvRlMPMX9K6tGT+WsklvKO5+2P6d9H2tSOS1odJvzpo1sxhkpazZP5aSQvU3r4t+v87Q0uyFdi6gv1I0iwsm8PMX5KWspICahd3/w6hY+i+z+1uqupM4EywCVzSoCybw8xfkpaykkt4HweOT/LA/jt2nkP3Ja+StBaYwyRNbOIWqKr6VpJfoPverwOAty76bjBJGixzmKSVWNXvwrMJXFqXdlTV5nkHsVLmL2ldWjJ/+SRySZKkRhZQkiRJjSygJEmSGllASZIkNbKAkiRJamQBJUmS1MgCSpIkqZEFlCRJUiMLKEmSpEYWUJIkSY0soCRJkhpZQEmSJDWygJIkSWpkASVJktTIAkqSJKmRBZQkSVIjCyhJkqRGFlCSJEmNLKAkSZIaWUBJkiQ1soCSJElqZAElSZLUyAJKkiSpkQWUJElSIwsoSZKkRhZQkiRJjSygJEmSGllASZIkNbKAkiRJamQBJUmS1MgCSpIkqdGyBVSStybZk+TykWlHJLk4yc7+/fDZhilJkzGHSZqFcVqgzgJOWzTtDGBbVR0PbOvHJWmIzsIcJmnKli2gqupDwJcWTX4GcHY/fDZw+nTDkqTpMIdJmoVJ+0AdVVW7Afr3I6cXkiTNnDlM0opsmPUOkmwFts56P5I0beYvSUuZtAXqxiQbAfr3PUstWFVnVtXmqto84b4kadrGymHmL0lLmbSAuhDY0g9vAS6YTjiStCrMYZJWZJzHGLwd+Cjw4CS7krwQeC1wapKdwKn9uCQNjjlM0iykqlZvZ8nq7UzSUOzYHy6Bmb+kdWnJ/OWTyCVJkhpZQEmSJDWygJIkSWpkASVJktTIAkqSJKmRBZQkSVIjCyhJkqRGFlCSJEmNLKAkSZIaWUBJkiQ1soCSJElqZAElSZLUyAJKkiSpkQWUJElSIwsoSZKkRhZQkiRJjTbMOwBJktaSqprq9pJMdXtaHbZASZIkNbKAkiRJamQBJUmS1Mg+UJKkdWXafZhWarl47CM1TLZASZIkNbKAkiRJamQBJUmS1Mg+UJKk/drQ+jy1Why/faKGwRYoSZKkRhZQkiRJjSygJEmSGtkHSpK0X1nrfZ60NtgCJUmS1GjZAirJsUk+mOTKJFckeWk//YgkFyfZ2b8fPvtwJWl85i9JszJOC9S3gJdV1UOBk4EXJ3kYcAawraqOB7b145I0JOYvSTOxbB+oqtoN7O6Hv5bkSuBo4BnAKf1iZwOXAK+cSZRasf29T4DPRdHemL/Wh/09v2mYmvpAJTkOOBG4FDiqT04LSerIqUcnSVNi/pI0TWPfhZfknsA7gV+qqq+Oe8afZCuwdbLwJGnlzF+Spm2sFqgkB9Iln3Oq6vx+8o1JNvbzNwJ79rZuVZ1ZVZuravM0ApakFuYvSbMwzl14Ad4CXFlVfzgy60JgSz+8Bbhg+uFJ0uTMX5JmJct1vkvyWOBvgU8Dd/STf4WuH8G5wP2Ba4FnVdWXltmWPf3mZH/vZGkn8kHbMa8WHPPX+rC/57fFzHerasn8tWwBNU0moPnZ3xOMCWXQ5lZATZP5a7j29/y2mPluVS2Zv3wSuSRJUiO/C0+SpDVkcYubLVLzYQuUJElSIwsoSZKkRhZQkiRJjewDJUkatPV2l91y7PM0DLZASZIkNbKAkiRJamQBJUmS1Mg+UJIkrSE+B2oYbIGSJElqZAElSZLUyAJKkiSpkX2gtF+wT4AkaTXZAiVJktTIAkqSJKmRBZQkSVIj+0Bpv2SfKEnSLNkCJUmS1MgCSpIkqZEFlCRJUiP7QGldsE+UtHYsPl6lIbIFSpIkqZEFlCRJUiMLKEmSpEb2gdK6ZJ8oSfsL89l82AIlSZLUyAJKkiSpkQWUJElSIwsoSZKkRhZQkiRJjZYtoJIcnORjSS5LckWS1/TTj0hycZKd/fvhsw9XksZn/pI0K+O0QN0GPL6qTgA2AaclORk4A9hWVccD2/pxSRoS85ekmVi2gKrO1/vRA/tXAc8Azu6nnw2cPosAJWlS5q+1oaru9pLWgrH6QCU5IMkngT3AxVV1KXBUVe0G6N+PnFmUkjQh85ekWRirgKqq26tqE3AMcFKSh4+7gyRbk2xPsn3CGCVpYuYvSbPQdBdeVd0MXAKcBtyYZCNA/75niXXOrKrNVbV5ZaFK0uTMX5KmaZy78O6b5LB++B7AE4GrgAuBLf1iW4ALZhSjJE3E/KX1yD5lq2OcLxPeCJyd5AC6guvcqrooyUeBc5O8ELgWeNYM45SkSZi/JM1EVrM6TWIpPCeeheyb314+Uzv2h0tg5q/ZMT/NlvltRZbMXz6JXJIkqdE4l/Ck/d5yZ8CewUnTY4vT6jK/zYYtUJIkSY0soCRJkhpZQEmSJDWyD5QkSfsx+zjNhi1QkiRJjSygJEmSGllASZIkNbKAkiRJamQBJUmS1MgCSpIkqZEFlCRJUiMLKEmSpEYWUJIkSY0soCRJkhpZQEmSJDWygJIkSWpkASVJktTIAkqSJKmRBZQkSVKjDfMOQJK0viS523hVzSkSaXK2QEmSJDWygJIkSWpkASVJktTIAkqSJKmRBZQkSVIjCyhJkqRGFlCSJEmNLKAkSZIaWUBJkiQ1GruASnJAkk8kuagfPyLJxUl29u+Hzy5MSZqc+UvStLW0QL0UuHJk/AxgW1UdD2zrxyVpiMxfkqZqrAIqyTHAjwBvHpn8DODsfvhs4PSpRiZJU2D+Gr4kd3tJa8G4LVCvA14B3DEy7aiq2g3Qvx853dAkaSpeh/lL0pQtW0AleSqwp6p2TLKDJFuTbE+yfZL1JWlS5i9Js7JhjGUeAzw9yVOAg4F7J/kL4MYkG6tqd5KNwJ69rVxVZwJnAiSpKcUtSeMwf0maiWVboKrqVVV1TFUdBzwH+EBV/RRwIbClX2wLcMHMopSkCZi/JM3KSp4D9Vrg1CQ7gVP7cUlaC8xfklYkVavXKm0T+Pys5u95f+SdQSuyo6o2zzuIlTJ/rR7z1XSZv1Zkyfzlk8glSZIajdOJXPuBxWcgnuFJkjQ5W6AkSZIaWUBJkiQ1soCSJElqZB+odco+UZKGyvyktcAWKEmSpEYWUJIkSY0soCRJkhrZB0rAyp9Uu7/1UfDJvdJwLHc87m/5p5X5aj5sgZIkSWpkASVJktTIAkqSJKmRfaAk7EMgrWXr7blR5qthsAVKkiSpkQWUJElSIwsoSZKkRvaB0lR4TV7SUKz0uVFD61Nlfh0mW6AkSZIaWUBJkiQ1soCSJElqZB8oSdK60tqnaLX7RNnnaW2wBUqSJKmRBZQkSVIjL+FJktTAS2wCW6AkSZKaWUBJkiQ1soCSJElqZAElSZLUyAJKkiSp0Vh34SW5BvgacDvwraranOQI4K+A44BrgGdX1ZdnE6YkTcb8JWkWWlqgHldVm6pqcz9+BrCtqo4HtvXjkjRE5i9JU7WSS3jPAM7uh88GTl9xNJK0OsxfklZk3AKqgPcn2ZFkaz/tqKraDdC/HzmLACVphcxfkqZu3CeRP6aqrk9yJHBxkqvG3UGfsLYuu6AkzYb5S9LUjdUCVVXX9+97gHcBJwE3JtkI0L/vWWLdM6tq80jfA0laNeYvSbOwbAGV5NAk91oYBp4EXA5cCGzpF9sCXDCrICVpEuYvSbMyziW8o4B39V+euAH4y6p6X5KPA+cmeSFwLfCs2YUpSRMxf0maiVTV6u0sWb2dSRqKHfvDJTDzl7QuLZm/fBK5JElSIwsoSZKkRhZQkiRJjSygJEmSGllASZIkNbKAkiRJamQBJUmS1MgCSpIkqZEFlCRJUiMLKEmSpEYWUJIkSY0soCRJkhpZQEmSJDWygJIkSWpkASVJktTIAkqSJKmRBZQkSVIjCyhJkqRGFlCSJEmNLKAkSZIaWUBJkiQ1soCSJElqZAElSZLUyAJKkiSpkQWUJElSIwsoSZKkRhZQkiRJjSygJEmSGllASZIkNbKAkiRJamQBJUmS1GisAirJYUnOS3JVkiuTPDrJEUkuTrKzfz981sFKUivzl6RZGLcF6vXA+6rqIcAJwJXAGcC2qjoe2NaPS9LQmL8kTV2qat8LJPcGLgMeVCMLJ7kaOKWqdifZCFxSVQ9eZlv73pmk/dGOqto8jx2bvySt0JL5a5wWqAcBXwTeluQTSd6c5FDgqKraDdC/Hzm1cCVpOsxfkmZinAJqA/BI4A1VdSJwCw3N3Um2JtmeZPuEMUrSpMxfkmZinAJqF7Crqi7tx8+jS0g39k3f9O979rZyVZ1ZVZvn1YQvaV0zf0maiWULqKq6AbguyUL/gCcAnwEuBLb007YAF8wkQkmakPlL0qxsGHO5lwDnJDkI+Dzw03TF17lJXghcCzxrNiFK0oqYvyRN3bJ34U11Z97FIq1Hc7sLb5rMX9K6tKK78CRJkjTCAkqSJKmRBZQkSVIjCyhJkqRGFlCSJEmNLKAkSZIaWUBJkiQ1soCSJElqZAElSZLUaNyvcpmWm4AvAPfph4dqyPENOTYYdnxDjg323/geMO1A5sT8NR1Djm/IscGw4xtybDCD/LWqX+Vy506T7UP+aochxzfk2GDY8Q05NjC+tWLon4PxTW7IscGw4xtybDCb+LyEJ0mS1MgCSpIkqdG8Cqgz57TfcQ05viHHBsOOb8ixgfGtFUP/HIxvckOODYYd35BjgxnEN5c+UJIkSWuZl/AkSZIarWoBleS0JFcn+VySM1Zz30vE89Yke5JcPjLtiCQXJ9nZvx8+x/iOTfLBJFcmuSLJS4cSY5KDk3wsyWV9bK8ZSmyL4jwgySeSXDS0+JJck+TTST6ZZPuQ4ktyWJLzklzV//09eiixzZM5rCm2weavPo7B5zDz18SxrUr+WrUCKskBwJ8ATwYeBjw3ycNWa/9LOAs4bdG0M4BtVXU8sK0fn5dvAS+rqocCJwMv7j+zIcR4G/D4qjoB2AScluTkgcQ26qXAlSPjQ4vvcVW1aeT22qHE93rgfVX1EOAEus9wKLHNhTms2ZDzF6yNHGb+mszq5K+qWpUX8Gjgr0fGXwW8arX2v4+4jgMuHxm/GtjYD28Erp53jCOxXQCcOrQYgUOAvwMeNaTYgGP6A+XxwEVD+/0C1wD3WTRt7vEB9wb+gb6P5JBim+fLHLbiOAeZv/o4BpfDzF8Tx7Vq+Ws1L+EdDVw3Mr6rnzY0R1XVboD+/cg5xwNAkuOAE4FLGUiMffPyJ4E9wMVVNZjYeq8DXgHcMTJtSPEV8P4kO5Js7acNIb4HAV8E3tZfPnhzkkMHEts8mcMmNMT81cc15Bz2Osxfk1i1/LWaBVT2Ms1bAMeQ5J7AO4FfqqqvzjueBVV1e1VtojtTOinJw+cc0p2SPBXYU1U75h3LPjymqh5Jd0noxUl+cN4B9TYAjwTeUFUnArcw/0sFQ2AOm8BQ8xcMN4eZv1Zk1fLXahZQu4BjR8aPAa5fxf2P68YkGwH69z3zDCbJgXTJ55yqOr+fPKgYq+pm4BK6vhhDie0xwNOTXAO8A3h8kr8YUHxU1fX9+x7gXcBJA4lvF7CrPxsHOI8uIQ0htnkyhzVaC/kLBpnDzF+TW7X8tZoF1MeB45M8MMlBwHOAC1dx/+O6ENjSD2+hu24/F0kCvAW4sqr+cGTW3GNMct8kh/XD9wCeCFw1hNgAqupVVXVMVR1H97f2gar6qaHEl+TQJPdaGAaeBFw+hPiq6gbguiQP7ic9AfjMEGKbM3NYgyHnLxh2DjN/TW5V89cqd+56CvBZ4O+BX13NfS8Rz9uB3cA36arWFwLfSddxb2f/fsQc43ss3SWCTwGf7F9PGUKMwCOAT/SxXQ68up8+99j2Eusp3NUJcxDx0V2nv6x/XbFwPAwovk3A9v73+27g8KHENue/JXPY+LENNn/18a2JHGb+mii+VclfPolckiSpkU8ilyRJamQBJUmS1MgCSpIkqZEFlCRJUiMLKEmSpEYWUJIkSY0soCRJkhpZQEmSJDX6f/v4ADZDWWc2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_predict=[]\n",
    "mask_gt=[]\n",
    "for i in range(len(val_dir)):\n",
    "    original_frames= val_gen[0][1][i]\n",
    "    original_frame=np.squeeze(original_frames)\n",
    "    mask_gt.append(original_frame)\n",
    "    predicted_frame= np.argmax(val_preds[i], axis=-1)\n",
    "    mask_predict.append(predicted_frame)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n",
    "    axes[0].imshow(original_frame, cmap=\"gray\")\n",
    "    axes[0].set_title(f\"Ground Truth: {val_dir[i]}\")\n",
    "    axes[1].imshow(predicted_frame, cmap=\"gray\")\n",
    "    axes[1].set_title(f\"Predicted: {val_dir[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "41bf689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DICE_COE(mask1, mask2):\n",
    "    intersect = np.sum(mask1*mask2)\n",
    "    fsum = np.sum(mask1)\n",
    "    ssum = np.sum(mask2)\n",
    "    dice = (2 * intersect ) / (fsum + ssum)\n",
    "    dice = np.mean(dice)\n",
    "    dice = round(dice, 3) # for easy reading\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "63e0c386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.689, 0.865]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice=[]\n",
    "for i in range(2):\n",
    "    dice.append(DICE_COE(mask_gt[i],mask_predict[i]))\n",
    "dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5219c8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 64)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(mask_predict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "30b1c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrrd.write(\"Unet_predictions\",np.array(mask_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
